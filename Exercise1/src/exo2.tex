\section*{Exercise 2} % (fold)
\label{sec:section_name}

\subsection*{a)} % (fold)
\label{sub:a}

Assuming that the language model uses a bigram and that the model $p(w_n,t_n|t_{n-1}, w_{n-1}, x_1^T)$ is given, 
we define:

\[
	Q(t,w) = \max_{\substack{w_1^n, t_1^n, n \\ w_n = w, t_n = t }} \prod_{k = 1}^n p(w_k,t_k|t_{k-1}, w_{k-1}, x_1^T)
\]

\subsection*{b)}%
\label{sub:b_}

Let's derive our recursive formula: 

\begin{align*}
	Q(t,w) &= \max_{\substack{w_1^n, t_1^n, n \\ w_n = w, t_n = t }} \prod_{k = 1}^n p(w_k,t_k|t_{k-1}, w_{k-1}, x_1^T) \\
		&= \max_{l \in \left[1,t-1\right],v}\max_{\substack{w_1^n, t_1^n, n \\ w_n = w, t_n = t \\ n-1, w_{n-1} = v, t_{n-1} = l }} \prod_{k = 1}^{n-1} p(w_k,t_k|t_{k-1}, w_{k-1}, x_1^t) p(w,t|l,v,x_1^l) \\
		&= \max_{l \in \left[1,t-1\right],v} Q(l,v) p(w,t|l,v,x_1^l)
\end{align*}


\subsection*{c)}%
\label{sub:c_}

We need to store both the best predecessor word for every word $V$ and its
word boundary $L$
\[
	(L,V)(t,w) = \text{argmax}_{l \in \left[1,t-1\right],v} Q(l,v) p(w,t|l,v,x_1^l) 
\]

\subsection*{d)}%
\label{sub:d_}

First, let's define some variables: 
\begin{itemize}
	\item $T$ = time length of signal
	\item $W$ = size of vocabulary
	\item $\overline{L}$ = average time length of word
\end{itemize}

The time complexity of dynamic programming is for a bigram $T \times T \times W \times W$,since we try out the language model recombination at every time t and word w for all wordsat every earlier word boundary time $l \le t - 1$.
Since one $T$ is always less than actual $T$ it will be a little smaller than the 
above mentioned.

The memory complexity of dynamic programming for a bigram is $2 \times T \times W$ since 
we need to store both $t$ and $w$ value for $L$ and $V$

